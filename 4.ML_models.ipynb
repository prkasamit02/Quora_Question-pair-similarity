{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VXPfRp-tARR",
    "outputId": "6c27acaf-2c6a-467f-fd7a-68efce98e30b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZihvUPvHtARd"
   },
   "source": [
    "<h1>4. Machine Learning Models </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtN9VBPutARf"
   },
   "source": [
    "<h2> 4.1 Reading data from file and storing into sql table </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owBQdjY1tARh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 rows\n",
      "360000 rows\n",
      "540000 rows\n"
     ]
    }
   ],
   "source": [
    "#Creating db file from csv\n",
    "if not os.path.isfile('train.db'):\n",
    "    disk_engine = create_engine('sqlite:///train.db')\n",
    "    start = dt.datetime.now()\n",
    "    chunksize = 180000\n",
    "    j = 0\n",
    "    index_start = 1\n",
    "    \n",
    "    for df in pd.read_csv('final_features.csv', names=['Unnamed: 0','id','is_duplicate','cwc_min','cwc_max','csc_min','csc_max','ctc_min','ctc_max','last_word_eq','first_word_eq','abs_len_diff','mean_len','token_set_ratio','token_sort_ratio','fuzz_ratio','fuzz_partial_ratio','longest_substr_ratio','freq_qid1','freq_qid2','q1len','q2len','q1_n_words','q2_n_words','word_Common','word_Total','word_share','freq_q1+q2','freq_q1-q2','0_x','1_x','2_x','3_x','4_x','5_x','6_x','7_x','8_x','9_x','10_x','11_x','12_x','13_x','14_x','15_x','16_x','17_x','18_x','19_x','20_x','21_x','22_x','23_x','24_x','25_x','26_x','27_x','28_x','29_x','30_x','31_x','32_x','33_x','34_x','35_x','36_x','37_x','38_x','39_x','40_x','41_x','42_x','43_x','44_x','45_x','46_x','47_x','48_x','49_x','50_x','51_x','52_x','53_x','54_x','55_x','56_x','57_x','58_x','59_x','60_x','61_x','62_x','63_x','64_x','65_x','66_x','67_x','68_x','69_x','70_x','71_x','72_x','73_x','74_x','75_x','76_x','77_x','78_x','79_x','80_x','81_x','82_x','83_x','84_x','85_x','86_x','87_x','88_x','89_x','90_x','91_x','92_x','93_x','94_x','95_x','0_y','1_y','2_y','3_y','4_y','5_y','6_y','7_y','8_y','9_y','10_y','11_y','12_y','13_y','14_y','15_y','16_y','17_y','18_y','19_y','20_y','21_y','22_y','23_y','24_y','25_y','26_y','27_y','28_y','29_y','30_y','31_y','32_y','33_y','34_y','35_y','36_y','37_y','38_y','39_y','40_y','41_y','42_y','43_y','44_y','45_y','46_y','47_y','48_y','49_y','50_y','51_y','52_y','53_y','54_y','55_y','56_y','57_y','58_y','59_y','60_y','61_y','62_y','63_y','64_y','65_y','66_y','67_y','68_y','69_y','70_y','71_y','72_y','73_y','74_y','75_y','76_y','77_y','78_y','79_y','80_y','81_y','82_y','83_y','84_y','85_y','86_y','87_y','88_y','89_y','90_y','91_y','92_y','93_y','94_y','95_y'],chunksize=chunksize, iterator=True, encoding='utf-8', ):\n",
    "        df.index += index_start\n",
    "        j+=1\n",
    "        print('{} rows'.format(j*chunksize))\n",
    "        df.to_sql('data', disk_engine, if_exists='append')\n",
    "        index_start = df.index[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hpD3aBktARn"
   },
   "outputs": [],
   "source": [
    "#http://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None \n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "\n",
    "def checkTableExists(dbcon):\n",
    "    cursr = dbcon.cursor()\n",
    "    str = \"select name from sqlite_master where type='table'\"\n",
    "    table_names = cursr.execute(str)\n",
    "    print(\"Tables in the databse:\")\n",
    "    tables =table_names.fetchall() \n",
    "    \n",
    "    return(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nR8ZIUnttARs",
    "outputId": "810fb3fb-7da2-4b78-9e29-9edabbf68cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the databse:\n"
     ]
    }
   ],
   "source": [
    "read_db = 'train.db'\n",
    "conn_r = create_connection(read_db)\n",
    "checkTableExists(conn_r)\n",
    "conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZq5gaaztARy"
   },
   "outputs": [],
   "source": [
    "# try to sample data according to the computing power you have\n",
    "if os.path.isfile(read_db):\n",
    "    conn_r = create_connection(read_db)\n",
    "    if conn_r is not None:\n",
    "        # for selecting first 1M rows\n",
    "       # data = pd.read_sql_query(\"\"\"SELECT * FROM data LIMIT 100001;\"\"\", conn_r)\n",
    "        \n",
    "        # for selecting random points\n",
    "        data = pd.read_sql_query(\"SELECT * From data ORDER BY RANDOM() LIMIT 100001;\", conn_r)\n",
    "        conn_r.commit()\n",
    "        conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461844</td>\n",
       "      <td>281842.0</td>\n",
       "      <td>281842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374995312558593</td>\n",
       "      <td>0.214284183684402</td>\n",
       "      <td>0.666655555740738</td>\n",
       "      <td>0.444439506227709</td>\n",
       "      <td>0.466663555576296</td>\n",
       "      <td>0.249999107146046</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>490069</td>\n",
       "      <td>310067.0</td>\n",
       "      <td>310067</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999966667777741</td>\n",
       "      <td>0.999966667777741</td>\n",
       "      <td>0.749981250468738</td>\n",
       "      <td>0.599988000239995</td>\n",
       "      <td>0.857130612419823</td>\n",
       "      <td>0.749990625117186</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>943448</td>\n",
       "      <td>403446.0</td>\n",
       "      <td>403446</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999950002499875</td>\n",
       "      <td>0.66664444518516</td>\n",
       "      <td>0.749981250468738</td>\n",
       "      <td>0.499991666805553</td>\n",
       "      <td>0.714275510349852</td>\n",
       "      <td>0.49999500005</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48608</td>\n",
       "      <td>48606.0</td>\n",
       "      <td>48606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399992000159997</td>\n",
       "      <td>0.153844970423304</td>\n",
       "      <td>0.117646366786078</td>\n",
       "      <td>0.0645159209163841</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497428</td>\n",
       "      <td>317426.0</td>\n",
       "      <td>317426</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199996000079998</td>\n",
       "      <td>0.166663888935184</td>\n",
       "      <td>0.999975000624984</td>\n",
       "      <td>0.571420408279882</td>\n",
       "      <td>0.555549382784636</td>\n",
       "      <td>0.384612426058261</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0      id is_duplicate            cwc_min  \\\n",
       "0  461844    281842.0  281842            0  0.374995312558593   \n",
       "1  490069    310067.0  310067            1  0.999966667777741   \n",
       "2  943448    403446.0  403446            0  0.999950002499875   \n",
       "3   48608     48606.0   48606            0                0.0   \n",
       "4  497428    317426.0  317426            0  0.199996000079998   \n",
       "\n",
       "             cwc_max            csc_min            csc_max            ctc_min  \\\n",
       "0  0.214284183684402  0.666655555740738  0.444439506227709  0.466663555576296   \n",
       "1  0.999966667777741  0.749981250468738  0.599988000239995  0.857130612419823   \n",
       "2   0.66664444518516  0.749981250468738  0.499991666805553  0.714275510349852   \n",
       "3                0.0  0.399992000159997  0.153844970423304  0.117646366786078   \n",
       "4  0.166663888935184  0.999975000624984  0.571420408279882  0.555549382784636   \n",
       "\n",
       "              ctc_max  ...   86_y  87_y  88_y  89_y  90_y  91_y  92_y  93_y  \\\n",
       "0   0.249999107146046  ...   None  None  None  None  None  None  None  None   \n",
       "1   0.749990625117186  ...   None  None  None  None  None  None  None  None   \n",
       "2       0.49999500005  ...   None  None  None  None  None  None  None  None   \n",
       "3  0.0645159209163841  ...   None  None  None  None  None  None  None  None   \n",
       "4   0.384612426058261  ...   None  None  None  None  None  None  None  None   \n",
       "\n",
       "   94_y  95_y  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkeBKktKtAR3"
   },
   "outputs": [],
   "source": [
    "# remove the first row \n",
    "data.drop(data.index[0], inplace=True)\n",
    "y_true = data['is_duplicate']\n",
    "data.drop(['Unnamed: 0', 'id','index','is_duplicate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKSenpsmtAR9",
    "outputId": "81d890ce-df79-4402-9324-84817dbd5a7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999966667777741</td>\n",
       "      <td>0.999966667777741</td>\n",
       "      <td>0.749981250468738</td>\n",
       "      <td>0.599988000239995</td>\n",
       "      <td>0.857130612419823</td>\n",
       "      <td>0.749990625117186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999950002499875</td>\n",
       "      <td>0.66664444518516</td>\n",
       "      <td>0.749981250468738</td>\n",
       "      <td>0.499991666805553</td>\n",
       "      <td>0.714275510349852</td>\n",
       "      <td>0.49999500005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399992000159997</td>\n",
       "      <td>0.153844970423304</td>\n",
       "      <td>0.117646366786078</td>\n",
       "      <td>0.0645159209163841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199996000079998</td>\n",
       "      <td>0.166663888935184</td>\n",
       "      <td>0.999975000624984</td>\n",
       "      <td>0.571420408279882</td>\n",
       "      <td>0.555549382784636</td>\n",
       "      <td>0.384612426058261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.249993750156246</td>\n",
       "      <td>0.166663888935184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124998437519531</td>\n",
       "      <td>0.090908264470323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cwc_min            cwc_max            csc_min            csc_max  \\\n",
       "1  0.999966667777741  0.999966667777741  0.749981250468738  0.599988000239995   \n",
       "2  0.999950002499875   0.66664444518516  0.749981250468738  0.499991666805553   \n",
       "3                0.0                0.0  0.399992000159997  0.153844970423304   \n",
       "4  0.199996000079998  0.166663888935184  0.999975000624984  0.571420408279882   \n",
       "5  0.249993750156246  0.166663888935184                0.0                0.0   \n",
       "\n",
       "             ctc_min             ctc_max last_word_eq first_word_eq  \\\n",
       "1  0.857130612419823   0.749990625117186          1.0           1.0   \n",
       "2  0.714275510349852       0.49999500005          0.0           0.0   \n",
       "3  0.117646366786078  0.0645159209163841          0.0           0.0   \n",
       "4  0.555549382784636   0.384612426058261          0.0           1.0   \n",
       "5  0.124998437519531   0.090908264470323          0.0           0.0   \n",
       "\n",
       "  abs_len_diff mean_len  ...   86_y  87_y  88_y  89_y  90_y  91_y  92_y  93_y  \\\n",
       "1          1.0      7.5  ...   None  None  None  None  None  None  None  None   \n",
       "2          3.0      8.5  ...   None  None  None  None  None  None  None  None   \n",
       "3         14.0     24.0  ...   None  None  None  None  None  None  None  None   \n",
       "4          4.0     11.0  ...   None  None  None  None  None  None  None  None   \n",
       "5          3.0      9.5  ...   None  None  None  None  None  None  None  None   \n",
       "\n",
       "   94_y  95_y  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  \n",
       "5  None  None  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KaWHDzqUtASD"
   },
   "source": [
    "<h2> 4.2 Converting strings to numerics </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLV60gkptASD",
    "outputId": "f297e0f4-52d5-4ab4-8a43-f0ff82f63698"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c8967109bea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# after we read from sql table each entry was read it as a string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# we convert all the features into numaric before we apply any model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# after we read from sql table each entry was read it as a string\n",
    "# we convert all the features into numaric before we apply any model\n",
    "cols = list(data.columns)\n",
    "for i in cols:\n",
    "    data[i] = data[i].apply(pd.to_numeric)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LpfQwc9tASJ"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7368789/convert-all-strings-in-a-list-to-int\n",
    "y_true = list(map(int, y_true.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuMTqWGutASO"
   },
   "source": [
    "<h2> 4.3 Random train test split( 70:30) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Rat2obGtASP"
   },
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(data, y_true, stratify=y_true, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Iw9zCHqtASS",
    "outputId": "910b684b-0876-4dd8-e0d9-457846236833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data : (70000, 218)\n",
      "Number of data points in test data : (30000, 218)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data :\",X_train.shape)\n",
    "print(\"Number of data points in test data :\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oDV15LJtASY",
    "outputId": "70a1e4eb-3f31-4f1e-a53b-ad972978505d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Distribution of output variable in train data ----------\n",
      "Class 0:  0.6310428571428571 Class 1:  0.3689571428571429\n",
      "---------- Distribution of output variable in train data ----------\n",
      "Class 0:  0.36893333333333334 Class 1:  0.36893333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "train_distr = Counter(y_train)\n",
    "train_len = len(y_train)\n",
    "print(\"Class 0: \",int(train_distr[0])/train_len,\"Class 1: \", int(train_distr[1])/train_len)\n",
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "test_distr = Counter(y_test)\n",
    "test_len = len(y_test)\n",
    "print(\"Class 0: \",int(test_distr[1])/test_len, \"Class 1: \",int(test_distr[1])/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfxcPT6jtASg"
   },
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UStQJ5F_tASk"
   },
   "source": [
    "<h2> 4.4 Building a random model (Finding worst-case log-loss) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwMDqcU7tASl",
    "outputId": "c1e90d53-25ec-445b-e33a-299538520e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss on Test Data using Random Model 0.885600630856617\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we need to generate 9 numbers and the sum of numbers should be 1\n",
    "# one solution is to genarate 9 numbers and divide each of the numbers by their sum\n",
    "# ref: https://stackoverflow.com/a/18662466/4084039\n",
    "# we create a output array that has exactly same size as the CV data\n",
    "predicted_y = np.zeros((test_len,2))\n",
    "for i in range(test_len):\n",
    "    rand_probs = np.random.rand(1,2)\n",
    "    predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Test Data using Random Model\",log_loss(y_test, predicted_y, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predicted_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgY29g_qtASq"
   },
   "source": [
    "<h2> 4.4 Logistic Regression with hyperparameter tuning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb2tOE3GtASr",
    "outputId": "d7e4fc88-7d4e-4313-cda7-462a2409292e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '  (0, 12299)\\t0.4002040468270767\\r\\n  (0, 1141)\\t0.38315415943433967\\r\\n  (0, 11607)\\t0.3616738416748856\\r\\n  (0, 9175)\\t0.28232219248274165\\r\\n  (0, 5490)\\t0.34752511807215414\\r\\n  (0, 11097)\\t0.3013282556652625\\r\\n  (0, 9186)\\t0.2721812806511078\\r\\n  (0, 9279)\\t0.2489363600815544\\r\\n  (0, 12548)\\t0.17098680976217684\\r\\n  (0, 7716)\\t0.17116767110039088\\r\\n  (0, 9411)\\t0.1532211570656206\\r\\n  (0, 7316)\\t0.1312820411735697\\r\\n  (0, 5385)\\t0.13544810183174477\\r\\n  (0, 1923)\\t0.10130098533312759\\r\\n  (0, 11803)\\t0.08388564037609605'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0561c5ad6caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0msig_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0msig_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    746\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\",\n\u001b[1;32m--> 570\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '  (0, 12299)\\t0.4002040468270767\\r\\n  (0, 1141)\\t0.38315415943433967\\r\\n  (0, 11607)\\t0.3616738416748856\\r\\n  (0, 9175)\\t0.28232219248274165\\r\\n  (0, 5490)\\t0.34752511807215414\\r\\n  (0, 11097)\\t0.3013282556652625\\r\\n  (0, 9186)\\t0.2721812806511078\\r\\n  (0, 9279)\\t0.2489363600815544\\r\\n  (0, 12548)\\t0.17098680976217684\\r\\n  (0, 7716)\\t0.17116767110039088\\r\\n  (0, 9411)\\t0.1532211570656206\\r\\n  (0, 7316)\\t0.1312820411735697\\r\\n  (0, 5385)\\t0.13544810183174477\\r\\n  (0, 1923)\\t0.10130098533312759\\r\\n  (0, 11803)\\t0.08388564037609605'"
     ]
    }
   ],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "X_test.fillna(X_train.mean(), inplace=True)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_train=l\n",
    "clf.fit(X_train, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouQSEnr3tASy"
   },
   "source": [
    "<h2> 4.5 Linear SVM with hyperparameter tuning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOFfZ5PLtAS0",
    "outputId": "d31eb598-e275-48cb-c49b-98e9eb76d8ba"
   },
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l1', loss='hinge', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l1', loss='hinge', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhTJgclztAS6"
   },
   "source": [
    "<h2> 4.6 XGBoost </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9U367-xetAS7",
    "outputId": "167e8588-2ac4-4c6d-ac22-f56a2fce5657"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_test, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "xgdmat = xgb.DMatrix(X_train,y_train)\n",
    "predict_y = bst.predict(d_test)\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6U5b17AatAS_",
    "outputId": "ca83b680-023b-4bc5-f499-8d8d85c2ff5e"
   },
   "outputs": [],
   "source": [
    "predicted_y =np.array(predict_y>0.5,dtype=int)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmiIgHOJtATF"
   },
   "source": [
    "<h1> 5. Assignments </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CWS6JoB0tATF"
   },
   "source": [
    "1. Try out models (Logistic regression, Linear-SVM) with simple TF-IDF vectors instead of TD_IDF weighted word2Vec.\n",
    "2. Hyperparameter tune XgBoost using RandomSearch to reduce the log-loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4.ML_models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
